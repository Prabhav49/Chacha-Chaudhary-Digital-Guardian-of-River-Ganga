<<<<<<< HEAD
import streamlit as st
from main import genai_engine
from streamlit_navigation_bar import st_navbar
import os
import speech_recognition as sr
import pyttsx3
from googletrans import Translator

st.set_page_config(page_title='Chacha Chaudhary: The Digital Guardian of Namami Gange', page_icon='C:\\Users\\nihar\\Downloads\\professor.png')

parent_dir = os.path.dirname(os.path.abspath(__file__))
logo_path = os.path.join(parent_dir, "nmcg_logo.svg")

text = ["Chacha Chaudhary: The Digital Guardian of Namami Gange"]
styles = {
    "nav": {
        "background-image": "linear-gradient(rgb(15, 18, 23), rgb(44, 62, 80))",
        "justify-content": "left",
        "height": "90px",
    },
    "img": {
        "padding-right": "8px",
        "height": "85px",
        "width": "175px",
    },
    "span": {
        "color": "white",
        "font-size": "34px",
        "width": "170%",
        "font-family": "Times New Roman",
    },
    "active": {
        "color": "white",
        "font-size": "34px",
        "width": "170%",
        "font-family": "Times New Roman",
    }
}
options = {
    "show_menu": False,
    "show_sidebar": False,
}

page = st_navbar(
    text,
    logo_path=logo_path,
    styles=styles,
    options=options,
)

st.header(" :blue[_Chacha Chaudhary's Gange Guide !_]", divider='rainbow')

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# Function for voice recognition
def recognize_speech():
    recognizer = sr.Recognizer()
    status_text = st.empty()  # Placeholder for status message
    status_text.write("Listening...")
    with sr.Microphone() as source:
        audio = recognizer.listen(source)
        status_text.write("Processing...")
    try:
        query = recognizer.recognize_google(audio)
    except sr.UnknownValueError:
        status_text.write("Sorry, I could not understand what you said.")
        query = ""
    finally:
        # Remove the status message
        status_text.empty()
    return query

# Function for text-to-speech
def text_to_speech(text, speed=150, language='en'):
    engine = pyttsx3.init()
    voices = engine.getProperty('voices')
    engine.setProperty('rate', speed)
    
    # Selecting a voice for the specified language
    for voice in voices:
        if language.lower() in voice.languages:
            engine.setProperty('voice', voice.id)
            break
    
    # For Hindi, set language property
    if language.lower() == 'hi':
        engine.setProperty('language', 'hi')
    
    engine.say(text)
    engine.runAndWait()

# Function to detect language
def detect_language(text):
    translator = Translator()
    return translator.detect(text).lang

# Function to translate text
def translate_text(text, dest_lang):
    translator = Translator()
    return translator.translate(text, dest=dest_lang).text

# Add button for voice input
if st.button("Speak"):
    prompt = recognize_speech()
    if prompt:
        user_inp = detect_language(prompt)
        if user_inp != 'en':
            disp_input = translate_text(prompt, 'hi')
            st.chat_message("user").markdown(disp_input)
        
        if user_inp == 'en':
            disp_input = translate_text(prompt, 'en')
            st.chat_message("user").markdown(disp_input)

        # Add user message to chat history
        st.session_state.messages.append({"role": "user", "content": prompt})

        # Detect language
        user_lang = detect_language(prompt)
        
        # Translate to English if not already in English
        if user_lang != 'en':
            prompt = translate_text(prompt, 'en')

        with st.spinner("Generating response..."):
            response = genai_engine(prompt)

        # Translate response to Hindi if the user's input language is Hindi
        if user_lang == 'hi':
            response = translate_text(response, 'hi')

        # Display assistant response and image in a horizontal layout
        st.write('<style>div.Widget.row-widget.stHorizontal</style>', unsafe_allow_html=True)
        col1, col2 = st.columns([1, 10])
        with col1:
            st.image("E:\\Chacha\\chacha_small.png", width=50)
        with col2:
            st.markdown(response)

        # Add assistant response to chat history
        st.session_state.messages.append({"role": "assistant", "content": response})

        # Convert text response to speech
        text_to_speech(response, speed=150, language=user_lang)

# React to user input
if prompt := st.chat_input("What is up?"):
    st.chat_message("user").markdown(prompt)
    # Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})

    # Detect language
    user_lang = detect_language(prompt)
    
    # Translate to English if not already in English
    if user_lang != 'en':
        prompt = translate_text(prompt, 'en')

    with st.spinner("Generating response..."):
        response = genai_engine(prompt)

    # Translate response to Hindi if the user's input language is Hindi
    if user_lang == 'hi':
        response = translate_text(response, 'hi')

    # Display assistant response and image in a horizontal layout
    st.write('<style>div.Widget.row-widget.stHorizontal</style>', unsafe_allow_html=True)
    col1, col2 = st.columns([1, 10])
    with col1:
        st.image("E:\\Chacha\\chacha_small.png", width=50)
    with col2:
        st.markdown(response)

    # Add assistant response to chat history
    st.session_state.messages.append({"role": "assistant", "content": response})

    # Convert text response to speech
    text_to_speech(response, speed=150, language=user_lang)
=======
import streamlit as st
from main import genai_engine
from streamlit_navigation_bar import st_navbar
import os
import speech_recognition as sr
import pyttsx3
from googletrans import Translator

st.set_page_config(page_title='Chacha Chaudhary: The Digital Guardian of Namami Gange', page_icon='C:\\Users\\nihar\\Downloads\\professor.png')

parent_dir = os.path.dirname(os.path.abspath(__file__))
logo_path = os.path.join(parent_dir, "nmcg_logo.svg")

text = ["Chacha Chaudhary: The Digital Guardian of Namami Gange"]
styles = {
    "nav": {
        "background-image": "linear-gradient(rgb(15, 18, 23), rgb(44, 62, 80))",
        "justify-content": "left",
        "height": "90px",
    },
    "img": {
        "padding-right": "8px",
        "height": "85px",
        "width": "175px",
    },
    "span": {
        "color": "white",
        "font-size": "34px",
        "width": "170%",
        "font-family": "Times New Roman",
    },
    "active": {
        "color": "white",
        "font-size": "34px",
        "width": "170%",
        "font-family": "Times New Roman",
    }
}
options = {
    "show_menu": False,
    "show_sidebar": False,
}

page = st_navbar(
    text,
    logo_path=logo_path,
    styles=styles,
    options=options,
)

st.header(" :blue[_Chacha Chaudhary's Gange Guide !_]", divider='rainbow')

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# Function for voice recognition
def recognize_speech():
    recognizer = sr.Recognizer()
    status_text = st.empty()  # Placeholder for status message
    status_text.write("Listening...")
    with sr.Microphone() as source:
        audio = recognizer.listen(source)
        status_text.write("Processing...")
    try:
        query = recognizer.recognize_google(audio)
    except sr.UnknownValueError:
        status_text.write("Sorry, I could not understand what you said.")
        query = ""
    finally:
        # Remove the status message
        status_text.empty()
    return query

# Function for text-to-speech
def text_to_speech(text, speed=150, language='en'):
    engine = pyttsx3.init()
    voices = engine.getProperty('voices')
    engine.setProperty('rate', speed)
    
    # Selecting a voice for the specified language
    for voice in voices:
        if language.lower() in voice.languages:
            engine.setProperty('voice', voice.id)
            break
    
    # For Hindi, set language property
    if language.lower() == 'hi':
        engine.setProperty('language', 'hi')
    
    engine.say(text)
    engine.runAndWait()

# Function to detect language
def detect_language(text):
    translator = Translator()
    return translator.detect(text).lang

# Function to translate text
def translate_text(text, dest_lang):
    translator = Translator()
    return translator.translate(text, dest=dest_lang).text

# Add button for voice input
if st.button("Speak"):
    prompt = recognize_speech()
    if prompt:
        user_inp = detect_language(prompt)
        if user_inp != 'en':
            disp_input = translate_text(prompt, 'hi')
            st.chat_message("user").markdown(disp_input)
        
        if user_inp == 'en':
            disp_input = translate_text(prompt, 'en')
            st.chat_message("user").markdown(disp_input)

        # Add user message to chat history
        st.session_state.messages.append({"role": "user", "content": prompt})

        # Detect language
        user_lang = detect_language(prompt)
        
        # Translate to English if not already in English
        if user_lang != 'en':
            prompt = translate_text(prompt, 'en')

        with st.spinner("Generating response..."):
            response = genai_engine(prompt)

        # Translate response to Hindi if the user's input language is Hindi
        if user_lang == 'hi':
            response = translate_text(response, 'hi')

        # Display assistant response and image in a horizontal layout
        st.write('<style>div.Widget.row-widget.stHorizontal</style>', unsafe_allow_html=True)
        col1, col2 = st.columns([1, 10])
        with col1:
            st.image("E:\\Chacha\\chacha_small.png", width=50)
        with col2:
            st.markdown(response)

        # Add assistant response to chat history
        st.session_state.messages.append({"role": "assistant", "content": response})

        # Convert text response to speech
        text_to_speech(response, speed=150, language=user_lang)

# React to user input
if prompt := st.chat_input("What is up?"):
    st.chat_message("user").markdown(prompt)
    # Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})

    # Detect language
    user_lang = detect_language(prompt)
    
    # Translate to English if not already in English
    if user_lang != 'en':
        prompt = translate_text(prompt, 'en')

    with st.spinner("Generating response..."):
        response = genai_engine(prompt)

    # Translate response to Hindi if the user's input language is Hindi
    if user_lang == 'hi':
        response = translate_text(response, 'hi')

    # Display assistant response and image in a horizontal layout
    st.write('<style>div.Widget.row-widget.stHorizontal</style>', unsafe_allow_html=True)
    col1, col2 = st.columns([1, 10])
    with col1:
        st.image("E:\\Chacha\\chacha_small.png", width=50)
    with col2:
        st.markdown(response)

    # Add assistant response to chat history
    st.session_state.messages.append({"role": "assistant", "content": response})

    # Convert text response to speech
    text_to_speech(response, speed=150, language=user_lang)
>>>>>>> 32e84ee0b39b60a128c7cace587dd13adbfd2aae
